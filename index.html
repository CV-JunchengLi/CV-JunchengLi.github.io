---
layout: home
author_profile: true
---

<h1 style="font-size: 1rem; font-weight: bold;">Juncheng Li (李俊诚)</h1>

<p style="font-size: 0.8rem;">
School of Computer Science & Technology</br> 
East China Normal University
</p>

<p style="font-size: 0.8rem;">
My google scholar is: <a href="https://scholar.google.com.hk/citations?user=a5jkbmkAAAAJ&hl=zh-CN", target="_blank">Juncheng Lsi (李俊诚)</a></br>
My researchgate is: <a href="https://www.researchgate.net/profile/Juncheng_Li5/publications", target="_blank">Juncheng Li</a></br> 
Long-term co-authors: Kangfu Mei, Aiwen Jiang, ZENG Tieyong, Qiaosi Yi.
</p>

<p style="font-size: 0.8rem;">
Email: cvjunchengli@gmail.com
</p>

<!-- <p style="font-size: 1rem; color:red">
Seeking a postdoctoral position! </br> 
Please contact me if you can provide this position.
</p> -->

<p></p>



<section style="font-size: 0.6rem;">
<h1 style="font-size: 1rem; font-weight: bold;">Biography</h1>
<p style="font-size: 0.8rem;">
I'm a Ph.D. student at School of Computer Science & Technology, East China Normal University (ECNU) and work with Prof. <b> <a href="https://scholar.google.com.hk/citations?user=dIfKlYgAAAAJ&hl=zh-CN", target="_blank"> Guixu Zhang</a></b> and Prof. <b><a href="https://scholar.google.com.hk/citations?user=TSkJe-4AAAAJ&hl=zh-CN", target="_blank">Faming Fang</a></b>. Meanwhile, I’m a member of the Shanghai Key Laboratory of Multidimensional Information Processing. I will graduate in 2021.07.</br>
</p>
</section>


<p></p>

<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Research Interests</h1>
    <li>
        Deep Learning, Computer Vision, Image Processing.
    </li>
    <li>
        Image restoration and enhancement, such as image super-resolution, image denoising, image dehazing, image demosaicing, image deblurring, and image enhancement.
    </li>
    <li>
        Image degradation, such as image compression and image decolorization.
    </li>
   
</section>

<p></p>


<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Recent News</h1>
    <li>
        One paper was submitted to NeurlPS 2020.</a>
    </li>
    <li>
        Two papers were submitted to ACM MM 2020, image stitching/image deblurring. (Guided)</a>
    </li>
    <li>
        One paper was submitted to IEEE TCSVT 2020, image super-resolution.</a>
    </li>
    <li>
        One paper was submitted to IEEE TMM 2020, low-light image enhancemen. (Guided)</a>
    </li>
    <li>
        One paper was submitted to IEEE TNNLS 2019, image denoising.</a>
    </li>
    <li>
        We have 1 paper accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6287639", target="_blank"> IEEE Access 2020</b></a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83", target="_blank"> TIP 2020</b></a>.
    </li>
    <li>
        We have 2 paper accepted to <a href="http://www.vision.ee.ethz.ch/aim19", target="_blank"> ICCV-AIM Workshop 2019</b></a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="https://sites.google.com/view/iccv-lci2019", target="_blank">ICCV-LCI Workshop 2019 <b>(Oral)</b></a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="http://digital-library.theiet.org/content/journals/iet-ipr/e-first", target="_blank">IET Image Processing 2019</a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="http://accv2018.net/dates/", target="_blank">ACCV 2018</a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="https://conference.cs.cityu.edu.hk/iconip/", target="_blank">ICONIP 2018</a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="https://eccv2018.org/", target="_blank">ECCV 2018</a>.
    </li>
    <li>
        We have 1 paper accepted to <a href="http://cvpr2018.thecvf.com/", target="_blank">CVPR-NTIRE Workshop 2018</a>.
    </li>
</section>

<p></p>

<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Research Experiences</h1>
    <li>
        I was an academic visitor at <a href="http://www.cuhk.edu.hk/chinese/index.html", target="_blank"> The Chinese University of HongKong (CUHK)</a> in 2019.8.16--2019.09.30 and worked with <a href="http://www.math.hkbu.edu.hk/~zeng/", target="_blank">Prof. ZENG Tieyong.</a> 
    </li>
    <li>
        I was a research assistant at <a href="http://www.cuhk.edu.hk/chinese/index.html", target="_blank">The Chinese University of HongKong (CUHK)</a> in 2018.05.10--2018.09.10 and worked with <a href="http://www.math.hkbu.edu.hk/~zeng/", target="_blank">Prof. ZENG Tieyong.</a> 
    </li>
</section>

<p></p>

<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Awards</h1>
    <li>
        ICCV Travel Award, 2019.
    </li>
    <li>
        We won the 1 place in <a href="http://www.vision.ee.ethz.ch/aim19/", target="_blank">"Example-based RAW to RGB Mapping Challenge, Track 2: Perceptual. (ICCV-AIM 2019)"</a>.
    </li>
    <li>
        We won the 2 place in <a href="http://www.vision.ee.ethz.ch/aim19/", target="_blank">"Example-based RAW to RGB Mapping Challenge, Track 1: Fidelity. (ICCV-AIM 2019)"</a>.
    </li>
    <li>
        We won the 4 place and "Geek Award" in <a href="https://tianchi.aliyun.com/competition/entrance/231711/introduction", target="_blank">"YouKu Video Super-resolution and Enhancement Challenge"</a> (4/1514).
    </li>
    <li>
        Top 30 Most Potential Developers prize in the 《2018 Computer Vision Most Potential Developers List》.
    </li>
    <li>
        We won the 3 place in <a href="https://github.com/rwenqi/ChinaMM18dehazing/blob/master/index.md", target="_blank">"ChinaMM 2018 Image Dehazing Challenge"</a>.
    </li>
    <li>
        We won the 6 place and awarded "Honorable Mention Award" in <a href="http://www.vision.ee.ethz.ch/ntire18/", target="_blank">"NTIRE 2018 Challenge on Image Dehazing"</a>.
    </li>
    <li>
        We won the 24 place in "JData algorithm competition" (Construction of the prediction model for the purchase intention of high potential users, 24/4240).
    </li>
</section>

<p></p>


<section style="font-size: 0.7rem;" class="publications">
    <h1 style="font-size: 1rem; font-weight: bold;">Journal Papers</h1>
    <li>
        <b>【1】 Soft-edge Assisted Network for Single Image Super-Resolution </b> </br>
        <a href="paper/TIP_2020.pdf", target="_blank">[Paper]</a>
        [Code]
        【SCI-1, IF=6.790】
        </br>
        <p style="margin: 0; padding-left: 1rem">Faming Fang, <u><b>Juncheng Li*</b></u>, and Tieyong Zeng</p>
        <p style="margin: 0; padding-left: 1rem"><font color="red">Author names alphabetically, <b>Main contributor*</b></font></p>
        <p style="margin: 0; padding-left: 1rem">East China Normal University, The Chinese University of Hong Kong</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">IEEE Transactions on Image Processing (TIP, <font color="red"><b>Top Journal</b></font>), 2020.</i> </br>
        <i style="font-size: 0.6rem; padding-left: 1rem">This achievement was completed during the visit of the Chinese University of Hong Kong.</i> </br>
    </li>
    <li>
        <b>【2】Progressive Back-traced Dehazing Network based on Multi-resolution Recurrent Reconstruction</b> </br>
        <a href="paper/Access_2020.pdf", target="_blank">[Paper]</a>
        [Code] 【SCI-2, IF=4.098】
        </br>
        <p style="margin: 0; padding-left: 1rem">Qiaosi Yi, Aiwen Jiang, <u><b>Juncheng Li</b></u>, Jianyi Wan, Mingwen Wang </p>
        <p style="margin: 0; padding-left: 1rem">Jiangxi Normal University, East China Normal University</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">IEEE Access, 2020</i></br>
    </li>
    <li>
        <b>【3】Deep Residual Refining based Pseudo Multi-frame Network for Effective Single Image Super-Resolution</b> </br>
        <a href="paper/IET_2018.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MKFMIKU/RPMNet", target="_blank">[Code]</a>
        【SCI-3, IF=2.004】
        </br>
        <p style="margin: 0; padding-left: 1rem">Aiwen Jiang, Kangfu Mei, <u><b>Juncheng Li</b></u>, Bo Liu, Jihua Ye and Mingwen Wang</p>
        <p style="margin: 0; padding-left: 1rem">Jiangxi Normal University, East China Normal University</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">IET Image Processing, 2019</i>

    </li>
</section>

<p></p>

<section style="font-size: 0.7rem;" class="publications">
    <h1 style="font-size: 1rem; font-weight: bold;">Conference Papers</h1>
    <li>
        <b>【1】Multi-scale Residual Network for Image Super-Resolution </b> </br>
        <!--.
        <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Juncheng_Li_Multi-scale_Residual_Network_ECCV_2018_paper.pdf">[Paper]</a>
        -->
        <a href="paper/ECCV_2018.pdf", target="_blank">[Paper]</a>
        <a href="poster/MSRN-poster.pdf", target="_blank">[Poster]</a>
        <a href="https://github.com/MIVRC/MSRN-PyTorch", target="_blank">[Code]</a>
        </br>
        <p style="margin: 0; padding-left: 1rem"><u><b>Juncheng Li</b></u>, Faming Fang, Kangfu Mei, and Guixu Zhang</p>
        <p style="margin: 0; padding-left: 1rem">East China Normal University, Jiangxi Normal University</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of European Conference on Computer Vision (ECCV, <font color="red"><b>Top Conference</b></font>), 2018.</i>
    </li>
    <li>
        <b>【2】Progressive Feature Fusion Network for Realistic Image Dehazing</b> </br>
        <a href="paper/ACCV_2018.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MIVRC/PFFNet-PyTorch", target="_blank">[Code]</a>
        </br>
        <p style="margin: 0; padding-left: 1rem">Kangfu Mei, Aiwen Jiang, <u><b>Juncheng Li</b></u>, and Mingwen Wang</p>
        <p style="margin: 0; padding-left: 1rem">Jiangxi Normal University, East China Normal University</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of Asian Conference on Computer Vision (ACCV), 2018.</i>
    </li>
    <li>
        <b>【3】An Effective Single-Image Super-Resolution Model Using Squeeze-and-Excitation Networks</b> </br>
        <a href="paper/ICONIP_2018.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MKFMIKU/SrSENet", target="_blank">[Code]</a>
        </br>
        <p style="margin: 0; padding-left: 1rem">Kangfu Mei, Aiwen Jiang, <u><b>Juncheng Li</b></u>, Jihua	Ye, and Mingwen Wang</p>
        <p style="margin: 0; padding-left: 1rem">Jiangxi Normal University, East China Normal University</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of International Conference on Neural Information Processing (ICONIP), 2018.</i>
    </li>

</section>

<p></p>

<section style="font-size: 0.7rem;" class="publications">
    <h1 style="font-size: 1rem; font-weight: bold;">Workshop Papers</h1>
    <li>
        <b>【1】Lightweight and Accurate Recursive Fractal Network for Image Super-Resolution </b> </br>
        <a href="paper/ICCVW_LCI_2019.pdf", target="_blank">[Paper]</a>
        <a href="poster/ICCVW_LCI_poster.pdf", target="_blank">[Poster]</a>
        <a href="slides/ICCVW_LCI_slides.pdf", target="_blank">[Slides]</a>
        <a href="https://github.com/MIVRC/SRRFN-PyTorch", target="_blank">[Code]</a>
        <font color="red">【Oral】</font>
        </br>
        <p style="margin: 0; padding-left: 1rem"><u><b>Juncheng Li</b></u>, Yiting Yuan, Kangfu Mei, and Faming Fang</p>
        <p style="margin: 0; padding-left: 1rem">East China Normal University, The Chinese University of Hong Kong (Shenzhen)</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of International Conference on Computer Vision Workshop (ICCVW), 2019.</i> </br>
        <i style="font-size: 0.6rem; padding-left: 1rem">Learning for Computational Imaging (LCI) Workshop</i>
    </li>
    <li>
        <b>【2】HighEr-Resolution Network for Image Demosaicing and Enhancing</b> </br>
        <a href="paper/ICCVW_AIM_2019.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MIVRC/HERN-PyTorch", target="_blank">[Code]</a>
        </br>
        <p style="margin: 0; padding-left: 1rem">Kangfu Mei, <u><b>Juncheng Li</b></u>, Jiajie Zhang, Haoyu Wu, Jie Li, Rui Huang </p>
        <p style="margin: 0; padding-left: 1rem">The Chinese University of Hong Kong (Shenzhen), East China Normal University</p>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of International Conference on Computer Vision Workshop (ICCVW), 2019.</i></br>
        <i style="font-size: 0.6rem; padding-left: 1rem">AIM: Advances in Image Manipulation workshop</i>
    </li>
    <li>
        <b>【3】AIM 2019 Challenge on Example-based RAW to RGB Mapping</b> </br>
        <a href="paper/ICCVW_2019.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MKFMIKU/RAW2RGBNet", target="_blank">[Code]</a>
        </br>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of International Conference on Computer Vision Workshop (ICCVW), 2019.</i></br>
        <i style="font-size: 0.6rem; padding-left: 1rem">AIM: Advances in Image Manipulation workshop</i>
    </li>
    <li>
        <b>【4】NTIRE 2018 Challenge on Image Dehazing: Methods and Results</b> </br>
        <a href="paper/CVPRW_2018.pdf", target="_blank">[Paper]</a>
        </br>
        <i style="font-size: 0.6rem; padding-left: 1rem">In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshop (CVPRW), 2018. </i></br>
        <i style="font-size: 0.6rem; padding-left: 1rem">New Trends in Image Restoration and Enhancement Workshop</i>
    </li>
</section>

<p></p>

<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Professional Service (Reviewer):</h1>
    <h1 style="font-size: 0.8rem; font-weight: bold;">Journal</h1>
    <li>
        IEEE Transactions on Image Processing (TIP)
    </li>
    <li>
        IEEE Transactions on Multimedia (TMM)
    </li>
    <li>
        IEEE Transactions on Emerging Topics in Computational Intelligence (TETCI)
    </li>
    <li>
        IEEE Access
    </li>
    <li>
        IEEE Signal Processing Letters (SPL)
    </li>
    <li>
        Signal Processing: Image Communication (SPIC)
    </li>
    <li>
        IET Computer Vision
    </li>
    <li>
        IET Signal Processing
    </li>
    <li>
        IET Image Processing
    </li>
    <li>
        IET Electronics Letters
    </li>
    <h1 style="font-size: 0.8rem; font-weight: bold;">Conference</h1>
    <li>
        British Machine Vision Conference (BMVC) 2020
    </li>
</section>


<p></p>

<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Social Activity</h1>
    <li>
        My friend and I build a WeChat Official Account named 【快乐AI】.
    </li>
    <li>
        I became a China Computer Federation member in 2019.
    </li>
    <li>
        I became a CVF member in 2019.
    </li>
    <li>
        My friend and I build a non-profit organization (<a href="https://github.com/MIVRC", target="_blank">MIVRC</a>) for open source image processing projects in 2019.
    </li>
    <li>
        I build CLFStudio 【丛林蜂工作室】 in 2015, a student studio dedicated to creative project development.
    </li>
</section>


<p></p>


<section style="font-size: 0.6rem;">
    <h1 style="font-size: 1rem; font-weight: bold;">Recommend</h1>
        <div align= "center">
        <b>My WeChat (please indicate the purpose)</b> </br>
        </div>
        <div align= "center">
            <img src="recommend/LJC.jpeg" width="200" height="200" /> 
        </div>

        <div align= "center">
        <b>WeChat Official Account (快乐AI)</b> </br>
       </div>
        <div align= "center">
            <img src="recommend/Happy_AI.jpeg" width="200" height="200" /> 
        </div>
    
</section>


<p></p>


<div>
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=lSzpjw-jyYmDQRUSrVJGAFZBVU3oVwp87NxUFm1Zt_w'></script>
</div>

<div align= "center">
<section style="font-size: 0.5rem;" class="publications"></section>
    <h1 style="font-size: 1rem; font-weight: bold;">Statistics from September 12, 2019</h1>
</section>
</div>

<style>
    .publications li {
        margin-bottom: 0.6rem;
    }
</style>
