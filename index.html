<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Juncheng Li, Li Juncheng, Juncheng, ECNU, East China Normal University, 李俊诚, 俊诚, 华东师范大学"> 
<meta name="description" content="Juncheng Li's home page">
<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Juncheng Li</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>

 <!-- <div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/CV-JunchengLi" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FD6C6C; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style> -->

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Juncheng Li (李俊诚)</h1> 
				</div>

				<h3> PhD Student </h3>
				<p>
					School of Computer Science and Technology<br>
					East China Normal University<br>
					3363 Zhongshan North Road,<br>
					Shanghai, China, 200062.<br>
					<br>
					ORCID: 0000-0001-7314-6754<br>
					Email: cvjunchengli@gmail.com 	       
				</p>

				<br>
				<p>
					<em>Success is not final, failure is not fatal, it is the courage to continue that counts.--Churchill</em>
				</p>

				<p> 
					<!-- <a href="https://github.com/CV-JunchengLi", target="_blank"><img src="./pic/cv_s.png" height="30px" style="margin-bottom:-3px"></a> -->
					<!-- <a href="JunchengLi-CV.pdf", target="_blank"><img src="./pic/cv_s.png" height="30px" style="margin-bottom:-3px"></a> -->
					<a href="https://scholar.google.com.hk/citations?user=a5jkbmkAAAAJ&hl=zh-CN", target="_blank"><img src="./pic/google_scholar.png" height="30px" style="margin-bottom:-3px"></a>
					<a href="https://github.com/CV-JunchengLi", target="_blank"><img src="./pic/github_s.jpg" height="30px" style="margin-bottom:-3px"></a>
					<a href="index_zw.html", target="_blank"><img src="./pic/zw.png" height="30px" style="margin-bottom:-3px"></a>
				</p><br>
			</td>
			<td>
				<img src="./pic/JunchengLi.jpeg" border="0" width="200"><br>
			</td>
		</tr>
		<tr>
		</tr>
	</tbody>
</table>

<h2>Biography</h2>
<p>
	I am a PhD student at the School of Computer Science and Technology, East China Normal University (ECNU), co-advised by Prof. <b> <a href="https://scholar.google.com.hk/citations?user=dIfKlYgAAAAJ&hl=zh-CN", target="_blank"> Guixu Zhang</a></b> and Prof. <b><a href="https://scholar.google.com.hk/citations?user=TSkJe-4AAAAJ&hl=zh-CN", target="_blank">Faming Fang</a></b>. I will graduate in 2021.07.
</p>

<p>My research interests include artificial intelligence and its applications to computer vision (e.g., image stitching, image segmentation, and crowd counting) and images processing (e.g., image super-resolution, image denoising, and image dehazing).</p>

<p>This web used to record my research achievement and also used to record my life experience.</p>


<h2>Honors &amp; Awards</h2>

<h3>2016-Now (Graduate Period)</h3>
<table style="border-spacing:2px">
	<tbody>
		<tr><td>Innovative and Intelligent Youth, East China Normal University, 2020. (0.5%)</td></tr> 	
		<tr><td>Outstanding Student, East China Normal University, 2020. (3.0%)</td></tr> 	
		<tr><td>Wisdom Scholarship, East China Normal University, 2020. (1.5%)</td></tr> 	
		<tr><td>Doctoral Research and Innovation Fund Project, East China Normal University, 2020.</td></tr> 	
		<tr><td>Graduate Scholarship, East China Normal University, 2016-2020.</td></tr> 	
		<tr><td>ICCV Travel Award, 2019.</td></tr> 	
		<tr><td> The 1st place in <a href="http://www.vision.ee.ethz.ch/aim19/", target="_blank">"Example-based RAW to RGB Mapping Challenge"</a>, Track 2: Perceptual. <b>(ICCV-AIM)</b>, 2019.</td></tr>
		<tr><td> The 2nd place in <a href="http://www.vision.ee.ethz.ch/aim19/", target="_blank">"Example-based RAW to RGB Mapping Challenge"</a>, Track 1: Fidelity. <b>(ICCV-AIM)</b>, 2019.</td></tr>
		<tr><td> The 4th place and "Geek Award" in Alibaba - <a href="https://tianchi.aliyun.com/competition/entrance/231711/introduction", target="_blank">"Youku Video Enhancement and Super Resolution Challenge"</a> <b>(4/1514)</b>, 2019.</td></tr>
		<tr><td> The 3rd place in China Multimedia - <a href="https://github.com/rwenqi/ChinaMM18dehazing/blob/master/index.md", target="_blank">"Image Dehazing Challenge"</a>, <b>(ChinaMM)</b>, 2018.</td></tr>
		<tr><td> The 6th place and "Honorable Mention Award" in <a href="http://www.vision.ee.ethz.ch/ntire18/", target="_blank">"Image Dehazing Challenge".</a> <b>(CVPR-NTIRE)</b>, 2018.</td></tr>
		<tr><td>Ranked 24th in Jingdong Algorithm Challenge - "Potential User Prediction" <b>(24/4240)</b>, 2017.</td></tr>
	</tbody>
</table>

<h3>2012-2016 (Undergraduate Period)</h3></tbody>
<table style="border-spacing:2px">
	<tbody>
		<tr><td>Mingde Scholarship, China, 2015. (3.0%)</td></tr> 
		<tr><td>Second Award in National Computer Design Contest, China, 2014, 2015.</td></tr> 
		<tr><td>Outstanding Graduates, Jiangxi Normal University, 2016.</td></tr> 
		<tr><td>Merit Student, Jiangxi Normal University, 2013-2016.</td></tr>
		<tr><td>Outstanding Student, Jiangxi Normal University, 2013-2016.</td></tr> 
		<tr><td>First-class Student Scholarship, Jiangxi Normal University, 2013-2016</td></tr> 
	</tbody>
</table>


<h2>Research Experience</h2>
<ul>
	<li>
		<div style="float:left; text-align:left">Shenzhen University, Shenzhen. </div> <div style="float:right; text-align:right">2020.12.11--2021.01.30</div><br>
		Research Assistant (RA)<br>
		Topic: Medical Image Segmentation & Research on Uncertainty in Deep Learning<br>
		Supervisor: Prof. <a href="http://www.hebmlc.org/", target="_blank">Xizhao Wang</a> (IEEE Fellow, CAAI Fellow, JMLC Editor-in-Chief)<br>
	</li>
	<li>
		<div style="float:left; text-align:left">The Chinese University of Hong Kong, Hong Kong. </div> <div style="float:right; text-align:right">2019.08.16--2019.09.30</div><br>
		Research Assistant (RA)<br>
		Topic: Image Compression<br>
		Supervisor: Prof. <a href="https://scholar.google.com.hk/citations?user=2yyTgRwAAAAJ&hl=zh-CN", target="_blank">ZENG Tieyong</a> (Director of <a href="http://cmai.math.cuhk.edu.hk/index.html">CMAI</a>)<br>
	</li>
	<li>
		<div style="float:left; text-align:left">The Chinese University of Hong Kong, Hong Kong. </div> <div style="float:right; text-align:right">2018.05.10--2018.09.10</div><br>
		Research Assistant (RA)<br>
		Topic: Image Restoration<br>
		Supervisor: Prof. <a href="https://scholar.google.com.hk/citations?user=2yyTgRwAAAAJ&hl=zh-CN", target="_blank">ZENG Tieyong</a> (Director of <a href="http://cmai.math.cuhk.edu.hk/index.html">CMAI</a>)<br>
	</li>
</ul>



<h2>Selected Publications </h2>
<h3>[Total Citations: 305] [Highest Citation: 175] [Total IF: 34.066] [Accepted: 13]</h3>
<h3>Accepted: ECCV, TNNLS, TIP, TCSVT, TMM, CVPRW, ICCVW, ACCV, etc.</h3>
<h3>Under Review: PR, TCSVT, TMM, ICME, etc.</h3>
<h4>Journal Papers</h4>
<table id="tbPublications" wßidth="100%">
	<tbody>
    <tr>	
		<td width="206">
		<img src="./indexpics/MDCN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TCSVT_2020.pdf" target="_blank">MDCN: Multi-scale Dense Cross Network for Image Super-Resolution</a><br>
		<b>Juncheng Li</b>, Faming Fang, Jiaqian Li, Kangfu Mei, and Guixu Zhang.
		<p><em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<i><b>IEEE TCSVT</b></i>), 2020. <br>
		<font color="red">Improved version of MSRN. SCI-2.</font><br>
        <a href="paper/TCSVT_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/MDCN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/TCSVT2020_MDCN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>


    <tr>	
		<td width="206">
		<img src="./indexpics/SeaNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TIP_2020.pdf" target="_blank">Soft-edge Assisted Network for Single Image Super-Resolution</a><br>
		Faming Fang, <b>Juncheng Li*</b>, and Tieyong Zeng.
		<p><em>IEEE Transactions on Image Processing</em> (<i><b>IEEE TIP</b></i>), 2020. <br>
		<font color="red">*First contributor, Author names alphabetically.</font><br> 
		<font color="red">This achievement was completed during the visit of the Chinese University of Hong Kong (CUHK). SCI-1, Top journal.</font><br> 
        <a href="paper/TIP_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/SeaNet-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/TIP2020_SEANET", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	

    <tr>	
		<td width="206">
		<img src="./indexpics/MLEFGN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TNNLS_2020.pdf" target="_blank">Multi-level Edge Features Guided Network for Image Denoising</a><br>
		Faming Fang, <b>Juncheng Li*</b>, Yiting Yuan, Tieyong Zeng, and Guixu Zhang.
		<p><em>IEEE Transactions on Neural Networks and Learning Systems</em> (<i><b>IEEE TNNLS</b></i>), 2020. <br>
		<font color="red">*First contributor, Author names alphabetically.</font><br> 
		<font color="red">This achievement was completed during the visit of the Chinese University of Hong Kong (CUHK). SCI-1, Top journal.</font><br> 
        <a href="paper/TNNLS_2020.pdf", target="_blank">[Paper]</a>
		<a href="https://github.com/MIVRC/MLEFGN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/TNNLS2020_MLEFGN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	


    <tr>	
		<td width="206">
		<img src="./indexpics/LPNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/TMM_2020.pdf" target="_blank">Luminance-aware Pyramid Network for Low-light Image Enhancement</a><br>
		Jiaqian Li#, <b>Juncheng Li#</b>, Faming Fang, Fang Li, and Guixu Zhang.
		<p><em>IEEE Transactions on Multimedia</em> (<i><b>IEEE TMM</b></i>), 2020. <br>
		<font color="red">#Equal Contribution. SCI-1.</font><br> 
		<a href="paper/TMM_2020.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
</tbody></table>

<h4>Conference Papers</h4></table>
<table id="tbPublications" width="100%">
    <tr>	
		<td width="206">
		<img src="./indexpics/HERN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="paper/ICCVW_AIM_2019.pdf" target="_blank">HighEr-Resolution Network for Image Demosaicing and Enhancing</a><br>
		Kangfu Mei, <b>Juncheng Li</b>, Jiajie Zhang, Haoyu Wu, Jie Li, and Rui Huang.
		<p><em>IInternational Conference on Computer Vision Workshop</em> (<i><b>ICCV Workshop</b></i>), 2019. <br>
		<font color="red">AIM2019 Winner</font><br> 
		<a href="paper/ICCVW_AIM_2019.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MIVRC/HERN-PyTorch", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	

	<tr>	
		<td width="206">
		<img src="./indexpics/SRRFN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/ICCVW_LCI_2019.pdf" target="_blank">Lightweight and Accurate Recursive Fractal Network for Image Super-Resolution</a><br>
		<b>Juncheng Li</b>, Yiting Yuan, Kangfu Mei, and Faming Fang.
		<p><em>International Conference on Computer Vision Workshop</em> (<i><b>ICCV Workshop</b></i>), 2019. <br>
		<font color="red">Oral Presentation</font><br>
		<a href="paper/ICCVW_LCI_2019.pdf", target="_blank">[Paper]</a>
        <a href="poster/ICCVW_LCI_poster.pdf", target="_blank">[Poster]</a>
        <a href="slides/ICCVW_LCI_slides.pdf", target="_blank">[Slides]</a>
		<a href="https://github.com/MIVRC/SRRFN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/ICCVW2019_SRRFN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


    <tr>	
		<td width="206">
		<img src="./indexpics/MSRN.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/ECCV_2018.pdf" target="_blank">Multi-scale Residual Network for Image Super-Resolution</a><br>
		<b>Juncheng Li</b>, Faming Fang, Kangfu Mei, and Guixu Zhang.
		<p><em>European Conference on Computer Vision</em> (<i><b>ECCV</b></i>), 2018.<br>
		<font color="red">Top CV conference. The most popular paper. 217 stars and 50 forks in Github.</font><br>
		<a href="paper/ECCV_2018.pdf", target="_blank">[Paper]</a>
        <a href="poster/MSRN-poster.pdf", target="_blank">[Poster]</a>
		<a href="https://github.com/MIVRC/MSRN-PyTorch", target="_blank">[Code]</a>
		<a href="https://junchenglee.com/projects/ECCV2018_MSRN", target="_blank">[Homepage]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	

    <tr>	
		<td width="206">
		<img src="./indexpics/PFFNet.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="paper/ACCV_2018.pdf" target="_blank">Progressive Feature Fusion Network for Realistic Image Dehazing</a><br>
		Kangfu Mei, Aiwen Jiang, <b>Juncheng Li</b>, and Mingwen Wang.
		<p><em>Asian Conference on Computer Vision</em> (<i><b>ACCV</b></i>), 2018.<br>
		<font color="red">The 3rd place in "ChinaMM2018 Image Dehazing Challenge"</font><br>
		<a href="paper/ACCV_2018.pdf", target="_blank">[Paper]</a>
        <a href="https://github.com/MIVRC/PFFNet-PyTorch", target="_blank">[Code]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
</tbody></table>


<h4>Preprints Papers</h4></table>
<table id="tbPublications" width="100%">
    <tr>	
		<td width="206">
		<img src="./indexpics/A1.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://arxiv.org/pdf/2006.13511.pdf" target="_blank">Disentangle Perceptual Learning through Online Contrastive Learning</a><br>
		Kangfu Mei, Yao Lu, Qiaosi Yi, Haoyu Wu, <b>Juncheng Li</b>, Rui Huang
		<p><em>arXiv preprint arXiv:2006.13511.</em><br>
		<a href="https://arxiv.org/pdf/2006.13511.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	<tr></tr>
	

	<tr>	
		<td width="206">
		<img src="./indexpics/A2.png" width="200" height = "120" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://arxiv.org/pdf/2101.01479.pdf" target="_blank">Scale-Aware Network with Regional and Semantic Attentions for Crowd Counting under Cluttered Background</a><br>
		Qiaosi Yi, Yunxing Liu, Aiwen Jiang, <b>Juncheng Li</b>, Kangfu Mei, Mingwen Wang
		<p><em>arXiv preprint arXiv:2101.01479.</em><br>
		<a href="https://arxiv.org/pdf/2101.01479.pdf", target="_blank">[Paper]</a>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	
</tbody></table>



<h2>Academic Services</h2>

<h3>Selected Reviewer</h3>
<h4>Journal</h4>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> IEEE Transactions on Image Processing (TIP, SCI-1) </td>
		</tr>
		<tr>
			<td> IEEE Transactions on Multimedia (TMM, SCI-1)</td>
		</tr>
        <tr>
			<td> Information Science (INS, SCI-1)</td>
		</tr>
		<tr>
			<td> Knowledge-Based Systems (KBS, SCI-1)</td>
		</tr>
		<tr>
			<td> IEEE Signal Processing Letters (SPL)</td>
		</tr>
		<tr>
			<td> IEEE Access</td>
		</tr>
	</tbody>
</table>

<h4>Conference</h4>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> International Conference on Multimedia and Expo (ICME)</td>
		</tr>
		<tr>
			<td> British Machine Vision Conference (BMVC)</td>
		</tr>
		<tr>
			<td> International Conference on Pattern Recognition (ICPR)</td>
		</tr>
	</tbody>
</table>


<h3>Association Member</h3>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> Member of the Computer Vision Foundation (CVF)</td>
		</tr>
		<tr>
			<td> Member of China Computer Federation (CCF)</td>
		</tr>
		<tr>
			<td> Member of the China Society of Image Graphics (CSIG)</td>
		</tr>
		<tr>
			<td> Member of the Chinese Association for Artificial Intelligence (CAAI)</td>
		</tr>
		<tr>
			<td> Founder of CLF Studio 【A non-profit student innovation studio】</td>
		</tr>
		<tr>
			<td> Founder of <a href="https://github.com/MIVRC", target="_blank">MIVRC</a> 【A non-profit image processing laboratory affiliated with CLF-AI】</td>
		</tr>
	</tbody>
</table>

<h2>Keynotes</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>	
			<td width="110">
				<img src="./reports/ICCV.png" width="100" style="box-shadow: 4px 4px 8px #888">
			</td>		
			<td> Lightweight and Accurate Recursive Fractal Network for Image Super-Resolution<br>
				<p><em>IEEE International Conference on Computer Vision</em> (<i><b>ICCV</b></i>).<br>
				Seoul, Korea, 2019.11.02.<br>
				<a href="slides/ICCVW_LCI_slides.pdf", target="_blank">[Slides]</a>
			</td>
		</tr>

		<tr>	
			<td width="110">
					<img src="./reports/SZ.png" width="100" style="box-shadow: 4px 4px 8px #888">
				</td>		
				<td> Exploration and Construction of Lightweight Image Restoration Model<br>
					<p><em>Institute of Big Data Technology and Application, School of Computer and Software, Shenzhen University.</em><br>
					Shenzhen, China, 2020.12.21.<br>
					<a href="poster/SZ.pdf", target="_blank">[Poster]</a>
					<a href="slides/SZ-Lightweight.pdf", target="_blank">[Slides]</a>
				</td>
			</tr>
	</tbody>
</table>

<h2>Meeting &amp; Visiting (2016.9-Now)</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td> <em>Research Assistant</em>, Shenzhen University, Shenzhen, China, 2020.</td>
		</tr>
		<tr>
			<td> Hunan University, Changsha, China, 2020.</td>
		</tr>
		<tr>
			<td> Hunan Normal University, Changsha, China, 2020.</td>
		</tr>
		<tr>
			<td> National Defense University, Changsha, China, 2020.</td>
		</tr>
		<tr>
			<td> CSIAM-2020, Changsha, China, 2020.</td>
		</tr>
        <tr>
			<td> PRCV-2020, Nanjing, China, 2020.</td>
		</tr>
		<tr>
			<td> SCF-2020, Shanghai, China, 2019.</td>
		</tr>
		<tr>
			<td> NeurlPS-Shanghai, Shanghai, China, 2019.</td>
		</tr>
		<tr>
			<td> Ewha Womans University, Seoul, Korea, 2019.</td>
		</tr>
		<tr>
			<td> ICCV-2019, Seoul, Korea, 2019.</td>
		</tr>
		<tr>
			<td> YouKu-VSRE-2019, Hanzhou, China, 2019.</td>
		</tr>
		<tr>
			<td> <em>Research Assistant</em>, The Chinese University of Hong Kong, Hong Kong, China, 2019.</td>
		</tr>
		<tr>
			<td> RAMIDS-2019, Shanghai Jiao Tong University, Shanghai, China, 2019.</td>
		</tr>
		<tr>
			<td> University of Science and Technology of China, Hefei, China, 2019.</td>
		</tr>
		<tr>
			<td> VALSE-2019, Hefei, China, 2019.</td>
		</tr>
		<tr>
			<td> Technical University of Munich, Munich, Germany, 2018.</td>
		</tr>
		<tr>
			<td> ECCV-2018, Munich, Germany, 2018.</td>
		</tr>
		<tr>
			<td> ECCV Pre-Conference, Tencent, Shenzhen, China, 2018.</td>
		</tr>
		<tr>
			<td> Macao Polytechnic Institut, Macao, China, 2018.</td>
		</tr>
		<tr>
			<td> The University of Hong Kong, Hong Kong, China, 2018.</td>
		</tr>
		<tr>
			<td> The Hong Kong University of Science and Technology, Hong Kong, China, 2018.</td>
		</tr>
		<tr>
			<td> The Hong Kong Polytechnic University, Hong Kong, China, 2018.</td>
		</tr>
		<tr>
			<td> The City University of Hong Kong, Hong Kong, China, 2018.</td>
		</tr>
		<tr>
			<td> THong Kong Baptist University, Hong Kong, China, 2018.</td>
		</tr>
		<tr>
			<td> <em>Research Assistant</em>, The Chinese University of Hong Kong, Hong Kong, China, 2018.</td>
		</tr>
		<tr>
			<td> AWS Reinvent, Shanghai, China, 2018.</td>
		</tr>
		<tr>
			<td> MICS-2017, Shanghai Jiao Tong University, Shanghai, China, 2017.</td>
		</tr>
		<tr>
			<td> FLAIR-2017, Shanghai, China, 2017.</td>
		</tr>
		<tr>
			<td> VALSE-2017, Xiamen University, Xiamen, China, 2017.</td>
		</tr>
		<tr>
			<td> Tianyuan Class, Zhejiang University, Hanzhou, China, 2017.</td>
		</tr>
		<tr>
			<td> ROS Class, East China University, Shanghai, China, 2017.</td>
		</tr>
		<tr>
			<td> MLA-2016, Nanjing University, Nanjing, China, 2016.</td>
		</tr>
		<tr>
			<td> Youth Vision Seminar, ShanghaiTech University, Shanghai, China, 2016.</td>
		</tr>
		<tr>
			<td> Fudan University, Shanghai, China, 2016.</td>
		</tr>
	</tbody>
</table>

<h2>Visited Cities</h2>
<table id="tbTeaching" border="0" width="100%">
	<tbody>
		<tr>
			<td><i><b>China</b></i>: Hong Kong, Macao, Beijing, Shanghai, Guangzhou, Shenzhen, Baoding, Hefei, Tianjin, Qingdao, Hangzhou, Jiaxing, Nanjing, Suzhou, Yangzhou, Lianyungang, Huaian, Wuxi, Shenyang, Changsha, Wuhan, Nanchang, Jiujiang, Shangrao, Jingdezhen, Xiamen, Fuzhou, Quanzhou, Putian.</td>
		</tr>
		<tr>
			<td><i><b>Germany</b></i>: Munich</td>
		</tr>
		<tr>
			<td><i><b>Korea</b></i>: Seoul</td>
		</tr>
	</tbody>
</table>

<div id="footer">
	<div id="footer-text"></div>
</div>

<p>
<center>
<div>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=lSzpjw-jyYmDQRUSrVJGAFZBVU3oVwp87NxUFm1Zt_w'></script>
</div>     
<br>
&copy; Juncheng Li | Last updated: 2021-01-09
</center>
</p>

</div>
</body></html>
